{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to my Docs","text":"<p>This is a documentation of code for my thesis project:</p> <p> \"3D point cloud analysis for traffic situational awareness\" </p> <p>The project consisted of creating an algorithm that will perform detection of dangerous situations on the road involving pedestrians. The creation of the project was accompanied by several stages:</p> <ul> <li>Getting to the LiDAR data - This was my first contact with any LiDAR. I was provided with data in the old hardware and firmware version. This required physically changing the contents of the metadata file.</li> <li>Conversion to matrix representation - A point cloud is an unstructured data type. For this reason, a conversion to an array representation and scaling was performed to use the detector.</li> <li>Creation of a dataset - I have created dataset of data converted to image by using Roboflow. The dataset is available here.</li> <li>Object detection - For this problem, I have used YOLOv8 convolution neural network. I have trained it on my dataset.</li> <li>Object tracking - For this problem, I have also used YOLOv8 with <code>ByteTrack</code> tracker.</li> <li>Creation of my own algorithm - This stage included selecting the point representing the detected object, filtering the \"measured\" data by <code>Kalman Filter</code> (docs). Then, with those data I have created conditional algorithm that was based on the position and speed of points between successive frames. That algorithm return priorities with messages:<ul> <li>0 - BREAK</li> <li>1 - SLOW DOWN</li> <li>2 - BE CAREFUL</li> <li>3 - GO AHEAD</li> </ul> </li> </ul> <p>As a result the algorithm takes the lowest priority and associated message of single frame.</p>"},{"location":"functions/","title":"Functions","text":"<p>Contain functions returning data.</p> <p>Logic of association priority with situation.</p>"},{"location":"functions/#functions.equations.danger_sit","title":"<code>danger_sit(out_x, out_y, id)</code>","text":"<p>Function returning priority and distance of situation.</p> <p>Parameters:</p> Name Type Description Default <code>out_x</code> <code>list</code> <p>List including X position and covered distance of pedestrian. </p> required <code>out_y</code> <code>list</code> <p>List including Y position and covered distance of pedestrian.</p> required <code>id</code> <code>int</code> <p>Identification of pedestrian.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple</code> <p>Priority and distance to the object.</p> Source code in <code>functions\\equations.py</code> <pre><code>def danger_sit(out_x:list, out_y:list, id:int) -&gt; tuple:\n    \"\"\"\n    Function returning priority and distance of situation.\n\n    Args:\n        out_x (list): List including X position and covered distance of pedestrian. \n        out_y (list): List including Y position and covered distance of pedestrian.\n        id (int): Identification of pedestrian.\n\n    Returns:\n        tuple: Priority and distance to the object. \n    \"\"\"\n    x_pos = out_x[0][0]\n    y_pos = out_y[0][0]\n    x_v = out_x[1][0]\n    y_v = out_y[1][0]\n\n    distance = math.sqrt(x_pos**2 + y_pos**2) - 1.5 # -1.5 because of the fact, that LiDAR is placed in the center of a car\n\n    p1 = (x_pos, y_pos)\n    p2 = (x_pos + x_v*DT, y_pos + y_v*DT)\n\n    a, b = linear_func_coefficients(p1, p2)\n\n    if a == 0:\n        a = EPS\n\n    l_s = (2-b)/a       # lower than 5 and greater than -2 \n    r_s = (-2-b)/a      #           -||-\n\n    f_s =  a*5 + b      # lower than 2 and greater than -2\n    b_s = a*(-2) + b    #           -||- \n\n    return cond_algorithm(left_side=l_s, right_side=r_s, front_side=f_s, back_side=b_s, \n                          x_pos=x_pos, x_velocity=x_v, y_pos=y_pos, y_velocity=y_v, distance=distance)\n</code></pre>"},{"location":"functions/#functions.equations.linear_func_coefficients","title":"<code>linear_func_coefficients(p1, p2)</code>","text":"<p>Function calculating line coefficients from two points.</p> <p>Parameters:</p> Name Type Description Default <code>p1</code> <code>tuple</code> <p>First point (XYZ) that represents pedestrian.</p> required <code>p2</code> <code>tuple</code> <p>Second point (XYZ) that represents pedestrian.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple</code> <p>Coefficients of the straight line coinciding with the pedestrian speed vector.</p> Source code in <code>functions\\equations.py</code> <pre><code>def linear_func_coefficients(p1:tuple, p2:tuple) -&gt; tuple:\n    \"\"\"\n    Function calculating line coefficients from two points.\n\n    Args:\n        p1 (tuple): First point (XYZ) that represents pedestrian.\n        p2 (tuple): Second point (XYZ) that represents pedestrian.\n\n    Returns:\n        tuple: Coefficients of the straight line coinciding with the pedestrian speed vector.\n    \"\"\"\n    if (p2[0] - p1[0]) == 0:\n        a = (p2[1]-p1[1])/(EPS)\n    else:\n        a = (p2[1]-p1[1])/(p2[0]-p1[0])\n    b = p1[1] - a*p1[0]\n    return a, b\n</code></pre>"},{"location":"functions/#functions.filters.kalman_filter","title":"<code>kalman_filter(init=0, v_init=0)</code>","text":"<p>Function implementing initialization of KalmanFilter</p> <p>Parameters:</p> Name Type Description Default <code>init</code> <code>float</code> <p>First X/Y coordinate of pedestrian. Defaults to 0.</p> <code>0</code> <code>v_init</code> <code>float</code> <p>First X/Y coordinate velocity of pedestrian. Defaults to 0.</p> <code>0</code> <p>Returns:</p> Name Type Description <code>KalmanFilter</code> <code>KalmanFilter</code> <p>KalmanFilter</p> Source code in <code>functions\\filters.py</code> <pre><code>def kalman_filter(init:float=0, v_init:float=0) -&gt; KalmanFilter:\n    \"\"\"\n    Function implementing initialization of KalmanFilter\n\n    Args:\n        init (float, optional): First X/Y coordinate of pedestrian. Defaults to 0.\n        v_init (float, optional): First X/Y coordinate velocity of pedestrian. Defaults to 0.\n\n    Returns:\n        KalmanFilter: KalmanFilter\n    \"\"\"\n    my_filter = KalmanFilter(dim_x=2, dim_z=1)  # dim_x: size of the state vector\n                                                # dim_z: size of the measurement vector\n\n    dt = 0.1\n    my_filter.x = np.array([[init, v_init]]).T     # x, vx\n\n    my_filter.F = np.array([[1, dt],      # state transition matrix\n                            [0, 1]])      \n\n    my_filter.H = np.array([[1, 0]])       # Measurement function    \n\n    my_filter.P = np.array([[1, 0],         # covariance matrix\n                            [0, 1]])       \n\n    my_filter.R = np.array([[0.1]])             # state uncertainty                  \n\n    my_filter.Q = Q_discrete_white_noise(dim=2, dt=dt, var=10) # process uncertainty\n\n    return my_filter\n</code></pre>"},{"location":"functions/#functions.conditional_algorithm.cond_algorithm","title":"<code>cond_algorithm(left_side, right_side, front_side, back_side, x_pos, x_velocity, y_pos, y_velocity, distance)</code>","text":"<p>Conditional algorithm of detecting car accident with pedestrian.</p> <p>Parameters:</p> Name Type Description Default <code>left_side</code> <code>float</code> <p>The intersection point of the pedestrian's speed vector with the left side of the vehicle.</p> required <code>right_side</code> <code>float</code> <p>The intersection point of the pedestrian's speed vector with the right side of the vehicle.</p> required <code>front_side</code> <code>float</code> <p>The intersection point of the pedestrian's speed vector with the front side of the vehicle.</p> required <code>back_side</code> <code>float</code> <p>The intersection point of the pedestrian's speed vector with the back side of the vehicle.</p> required <code>x_pos</code> <code>float</code> <p>Value of X coordinate of pedestrian in cartesian coordinate system.</p> required <code>x_velocity</code> <code>float</code> <p>Value of X coordinate velocity.</p> required <code>y_pos</code> <code>float</code> <p>Value of Y coordinate of pedestrian in cartesian coordinate system.</p> required <code>y_velocity</code> <code>float</code> <p>Value of Y coordinate velocity.</p> required <code>distance</code> <code>float</code> <p>Distance from car to pedestrian.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple</code> <p>priority and distance to the object</p> Source code in <code>functions\\conditional_algorithm.py</code> <pre><code>def cond_algorithm(left_side:float, right_side:float, front_side:float, back_side:float, \n                   x_pos:float, x_velocity:float, y_pos:float, y_velocity:float, distance:float) -&gt; tuple:\n    \"\"\"\n    Conditional algorithm of detecting car accident with pedestrian.\n\n    Args:\n        left_side (float): The intersection point of the pedestrian's speed vector with the left side of the vehicle.\n        right_side (float): The intersection point of the pedestrian's speed vector with the right side of the vehicle.\n        front_side (float): The intersection point of the pedestrian's speed vector with the front side of the vehicle.\n        back_side (float): The intersection point of the pedestrian's speed vector with the back side of the vehicle.\n        x_pos (float): Value of X coordinate of pedestrian in cartesian coordinate system.\n        x_velocity (float): Value of X coordinate velocity.\n        y_pos (float): Value of Y coordinate of pedestrian in cartesian coordinate system.\n        y_velocity (float): Value of Y coordinate velocity.\n        distance (float): Distance from car to pedestrian.\n\n    Returns:\n        tuple: priority and distance to the object \n    \"\"\"\n\n    if (-2 &lt; left_side &lt; 5) or (-2 &lt; right_side &lt; 5) or (-3 &lt; front_side &lt; 3) or (-3 &lt; back_side &lt; 3):\n        if x_velocity &gt; 0 :\n            if distance &lt; 5 :\n                return 3, distance\n            else:\n                return 2, distance\n        else:\n            if 0 &lt; x_pos &lt; 30:\n                if -7 &lt; y_pos &lt; 7:\n                    if x_velocity &gt; -2:\n                        return 2, distance\n                    elif x_velocity &gt; -4:\n                        return 1, distance\n                    else:\n                        return 0, distance\n                else:\n                    return 3, distance\n            else: \n                    return 3, distance\n    else:\n        if 0 &lt; x_pos &lt; 20:\n            if -2 &lt; y_pos &lt; 2:\n                return 2, distance\n            else:\n                return 3, distance\n        else:\n            return 3, distance\n</code></pre>"},{"location":"read_lidar/","title":"Read Lidar","text":"<p>File containing all created classes. </p>"},{"location":"read_lidar/#read_lidar.DataHandler","title":"<code>DataHandler</code>","text":"<p>Class for some data.</p> Source code in <code>read_lidar.py</code> <pre><code>class DataHandler:\n    \"\"\"\n    Class for some data.\n    \"\"\"\n    def __init__(self, metadata_path, pcap_path):\n        \"\"\"\n        Initialization.\n\n        Args:\n            metadata_path (str): Path to `.json` file.\n            pcap_path (str): Path to `.pcap` file.\n        \"\"\"\n        self.metadata = SensorInfo(open(metadata_path, 'r').read())\n        self.pcap_file = pcap.Pcap(pcap_path, self.metadata)\n        self.xyz_lut = client.XYZLut(self.metadata)\n        self.fps = int(str(self.metadata.mode)[-2:])\n        self.width = int(str(self.metadata.mode)[:4])\n        self.height = int(str(self.metadata.prod_line)[5:])\n        self.output_dict = {3:[\"GO AHEAD\", (0, 255, 0)], 2:[\"BE CAREFUL\", (0, 155, 100)], 1:[\"SLOW DOWN\", (0, 100, 155)], \n                   0:[\"BREAK\", (0, 0, 255)]}\n\n    def get_metadata(self):\n        \"\"\"\n        Return `SensorInfo` object.\n\n        Returns:\n            (SensorInfo): Metadata.\n        \"\"\"\n        return self.metadata\n\n    def get_scans(self):\n        \"\"\"\n        Return `Scans` object.\n\n        Returns:\n            (Scans): Scans.\n        \"\"\"\n        scans = Scans(self.pcap_file)\n        return scans\n\n    def get_output_dict(self):\n        \"\"\"\n        Return output dictionary (priority and associated message).\n\n        Returns:\n            (dict): output_dict.\n        \"\"\"\n        return self.output_dict\n\n    def get_xyz_lut(self):\n        \"\"\"\n        Return xyz lookup table for transforming to cartesian coordinate system.\n\n        Returns:\n            (XYZLut): xyz_lut.\n        \"\"\"\n        return self.xyz_lut\n\n    def get_video_params(self):\n        \"\"\"\n        Return parameters required for saving a video.\n\n        Returns:\n            (tuple): fps, image width, image height\n        \"\"\"\n        return self.fps, self.width, self.height\n</code></pre>"},{"location":"read_lidar/#read_lidar.DataHandler.__init__","title":"<code>__init__(metadata_path, pcap_path)</code>","text":"<p>Initialization.</p> <p>Parameters:</p> Name Type Description Default <code>metadata_path</code> <code>str</code> <p>Path to <code>.json</code> file.</p> required <code>pcap_path</code> <code>str</code> <p>Path to <code>.pcap</code> file.</p> required Source code in <code>read_lidar.py</code> <pre><code>def __init__(self, metadata_path, pcap_path):\n    \"\"\"\n    Initialization.\n\n    Args:\n        metadata_path (str): Path to `.json` file.\n        pcap_path (str): Path to `.pcap` file.\n    \"\"\"\n    self.metadata = SensorInfo(open(metadata_path, 'r').read())\n    self.pcap_file = pcap.Pcap(pcap_path, self.metadata)\n    self.xyz_lut = client.XYZLut(self.metadata)\n    self.fps = int(str(self.metadata.mode)[-2:])\n    self.width = int(str(self.metadata.mode)[:4])\n    self.height = int(str(self.metadata.prod_line)[5:])\n    self.output_dict = {3:[\"GO AHEAD\", (0, 255, 0)], 2:[\"BE CAREFUL\", (0, 155, 100)], 1:[\"SLOW DOWN\", (0, 100, 155)], \n               0:[\"BREAK\", (0, 0, 255)]}\n</code></pre>"},{"location":"read_lidar/#read_lidar.DataHandler.get_metadata","title":"<code>get_metadata()</code>","text":"<p>Return <code>SensorInfo</code> object.</p> <p>Returns:</p> Type Description <code>SensorInfo</code> <p>Metadata.</p> Source code in <code>read_lidar.py</code> <pre><code>def get_metadata(self):\n    \"\"\"\n    Return `SensorInfo` object.\n\n    Returns:\n        (SensorInfo): Metadata.\n    \"\"\"\n    return self.metadata\n</code></pre>"},{"location":"read_lidar/#read_lidar.DataHandler.get_output_dict","title":"<code>get_output_dict()</code>","text":"<p>Return output dictionary (priority and associated message).</p> <p>Returns:</p> Type Description <code>dict</code> <p>output_dict.</p> Source code in <code>read_lidar.py</code> <pre><code>def get_output_dict(self):\n    \"\"\"\n    Return output dictionary (priority and associated message).\n\n    Returns:\n        (dict): output_dict.\n    \"\"\"\n    return self.output_dict\n</code></pre>"},{"location":"read_lidar/#read_lidar.DataHandler.get_scans","title":"<code>get_scans()</code>","text":"<p>Return <code>Scans</code> object.</p> <p>Returns:</p> Type Description <code>Scans</code> <p>Scans.</p> Source code in <code>read_lidar.py</code> <pre><code>def get_scans(self):\n    \"\"\"\n    Return `Scans` object.\n\n    Returns:\n        (Scans): Scans.\n    \"\"\"\n    scans = Scans(self.pcap_file)\n    return scans\n</code></pre>"},{"location":"read_lidar/#read_lidar.DataHandler.get_video_params","title":"<code>get_video_params()</code>","text":"<p>Return parameters required for saving a video.</p> <p>Returns:</p> Type Description <code>tuple</code> <p>fps, image width, image height</p> Source code in <code>read_lidar.py</code> <pre><code>def get_video_params(self):\n    \"\"\"\n    Return parameters required for saving a video.\n\n    Returns:\n        (tuple): fps, image width, image height\n    \"\"\"\n    return self.fps, self.width, self.height\n</code></pre>"},{"location":"read_lidar/#read_lidar.DataHandler.get_xyz_lut","title":"<code>get_xyz_lut()</code>","text":"<p>Return xyz lookup table for transforming to cartesian coordinate system.</p> <p>Returns:</p> Type Description <code>XYZLut</code> <p>xyz_lut.</p> Source code in <code>read_lidar.py</code> <pre><code>def get_xyz_lut(self):\n    \"\"\"\n    Return xyz lookup table for transforming to cartesian coordinate system.\n\n    Returns:\n        (XYZLut): xyz_lut.\n    \"\"\"\n    return self.xyz_lut\n</code></pre>"},{"location":"read_lidar/#read_lidar.HistoryTracker","title":"<code>HistoryTracker</code>","text":"<p>Class for remembering track history.</p> Source code in <code>read_lidar.py</code> <pre><code>class HistoryTracker:\n    \"\"\"\n    Class for remembering track history.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initialization.\n        \"\"\"\n        self.history = defaultdict(lambda: [])\n\n    def update_history(self, id, xyz_val):\n        \"\"\"\n        Appending coordinates of object to track.\n\n        Args:\n            id (int): _description_\n            xyz_val (list): _description_\n        \"\"\"\n        track = self.history[id]\n        if len(track) &gt; 0:\n            if xyz_val[0] == 0 or xyz_val[1] == 0:\n                track.append(track[-1])\n            else:\n                track.append(xyz_val)\n        else:\n            track.append(xyz_val)\n\n    def get_history(self):\n        \"\"\"Return track history.\n\n        Returns:\n            (defaultdict): dict with keys: `id`, values: lists of points.\n        \"\"\"\n        return self.history\n\n    def get_track(self, id):\n        \"\"\"Return object track history.\n\n        Args:\n            id (int): object's id\n\n        Returns:\n            (list): list of points\n        \"\"\"\n        return self.history[id]\n</code></pre>"},{"location":"read_lidar/#read_lidar.HistoryTracker.__init__","title":"<code>__init__()</code>","text":"<p>Initialization.</p> Source code in <code>read_lidar.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Initialization.\n    \"\"\"\n    self.history = defaultdict(lambda: [])\n</code></pre>"},{"location":"read_lidar/#read_lidar.HistoryTracker.get_history","title":"<code>get_history()</code>","text":"<p>Return track history.</p> <p>Returns:</p> Type Description <code>defaultdict</code> <p>dict with keys: <code>id</code>, values: lists of points.</p> Source code in <code>read_lidar.py</code> <pre><code>def get_history(self):\n    \"\"\"Return track history.\n\n    Returns:\n        (defaultdict): dict with keys: `id`, values: lists of points.\n    \"\"\"\n    return self.history\n</code></pre>"},{"location":"read_lidar/#read_lidar.HistoryTracker.get_track","title":"<code>get_track(id)</code>","text":"<p>Return object track history.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>int</code> <p>object's id</p> required <p>Returns:</p> Type Description <code>list</code> <p>list of points</p> Source code in <code>read_lidar.py</code> <pre><code>def get_track(self, id):\n    \"\"\"Return object track history.\n\n    Args:\n        id (int): object's id\n\n    Returns:\n        (list): list of points\n    \"\"\"\n    return self.history[id]\n</code></pre>"},{"location":"read_lidar/#read_lidar.HistoryTracker.update_history","title":"<code>update_history(id, xyz_val)</code>","text":"<p>Appending coordinates of object to track.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>int</code> <p>description</p> required <code>xyz_val</code> <code>list</code> <p>description</p> required Source code in <code>read_lidar.py</code> <pre><code>def update_history(self, id, xyz_val):\n    \"\"\"\n    Appending coordinates of object to track.\n\n    Args:\n        id (int): _description_\n        xyz_val (list): _description_\n    \"\"\"\n    track = self.history[id]\n    if len(track) &gt; 0:\n        if xyz_val[0] == 0 or xyz_val[1] == 0:\n            track.append(track[-1])\n        else:\n            track.append(xyz_val)\n    else:\n        track.append(xyz_val)\n</code></pre>"},{"location":"read_lidar/#read_lidar.HistoryTrackerXY","title":"<code>HistoryTrackerXY</code>","text":"<p>Class for filtering track</p> Source code in <code>read_lidar.py</code> <pre><code>class HistoryTrackerXY:\n    \"\"\"Class for filtering track\n    \"\"\"\n    def __init__(self):\n        \"\"\"_summary_\n        \"\"\"\n        self.x = {}\n        self.y = {}\n\n    def update(self, track, id):\n        \"\"\"Updating KalamanFilter object, predicting next point. \n\n        Args:\n            track (list): track of object\n            id (int): object's id\n        \"\"\"\n        value = self.x.get(id)\n        if value is None:\n            x_0 = track[0][0]\n            y_0 = track[0][1]\n            vx_0 = (track[1][0] - x_0)/0.1\n            vy_0 = (track[1][1] - y_0)/0.1\n\n            self.x[id] = kalman_filter(init=x_0, v_init=vx_0)\n            self.y[id] = kalman_filter(init=y_0, v_init=vy_0)\n            x = self.x[id]\n            y = self.y[id]\n        else:\n            x = self.x[id]\n            y = self.y[id]\n        x.predict()\n        y.predict()\n        x.update([track[-1][0]])\n        y.update([track[-1][1]])\n\n    def get_x_data(self, id):\n        \"\"\"Return x coordinate value and velocity after filtering\n\n        Args:\n            id (int): object's id\n\n        Returns:\n            (KelmanFilter.x): predicted values related to x coordinate\n        \"\"\"\n        return self.x[id].x\n\n    def get_y_data(self, id):\n        \"\"\"Return y coordinate value and velocity after filtering\n\n        Args:\n            id (int): object's id\n\n        Returns:\n            (KelmanFilter.x): predicted values related to y coordinate\n        \"\"\"\n        return self.y[id].x\n</code></pre>"},{"location":"read_lidar/#read_lidar.HistoryTrackerXY.__init__","title":"<code>__init__()</code>","text":"<p>summary</p> Source code in <code>read_lidar.py</code> <pre><code>def __init__(self):\n    \"\"\"_summary_\n    \"\"\"\n    self.x = {}\n    self.y = {}\n</code></pre>"},{"location":"read_lidar/#read_lidar.HistoryTrackerXY.get_x_data","title":"<code>get_x_data(id)</code>","text":"<p>Return x coordinate value and velocity after filtering</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>int</code> <p>object's id</p> required <p>Returns:</p> Type Description <code>x</code> <p>predicted values related to x coordinate</p> Source code in <code>read_lidar.py</code> <pre><code>def get_x_data(self, id):\n    \"\"\"Return x coordinate value and velocity after filtering\n\n    Args:\n        id (int): object's id\n\n    Returns:\n        (KelmanFilter.x): predicted values related to x coordinate\n    \"\"\"\n    return self.x[id].x\n</code></pre>"},{"location":"read_lidar/#read_lidar.HistoryTrackerXY.get_y_data","title":"<code>get_y_data(id)</code>","text":"<p>Return y coordinate value and velocity after filtering</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>int</code> <p>object's id</p> required <p>Returns:</p> Type Description <code>x</code> <p>predicted values related to y coordinate</p> Source code in <code>read_lidar.py</code> <pre><code>def get_y_data(self, id):\n    \"\"\"Return y coordinate value and velocity after filtering\n\n    Args:\n        id (int): object's id\n\n    Returns:\n        (KelmanFilter.x): predicted values related to y coordinate\n    \"\"\"\n    return self.y[id].x\n</code></pre>"},{"location":"read_lidar/#read_lidar.HistoryTrackerXY.update","title":"<code>update(track, id)</code>","text":"<p>Updating KalamanFilter object, predicting next point. </p> <p>Parameters:</p> Name Type Description Default <code>track</code> <code>list</code> <p>track of object</p> required <code>id</code> <code>int</code> <p>object's id</p> required Source code in <code>read_lidar.py</code> <pre><code>def update(self, track, id):\n    \"\"\"Updating KalamanFilter object, predicting next point. \n\n    Args:\n        track (list): track of object\n        id (int): object's id\n    \"\"\"\n    value = self.x.get(id)\n    if value is None:\n        x_0 = track[0][0]\n        y_0 = track[0][1]\n        vx_0 = (track[1][0] - x_0)/0.1\n        vy_0 = (track[1][1] - y_0)/0.1\n\n        self.x[id] = kalman_filter(init=x_0, v_init=vx_0)\n        self.y[id] = kalman_filter(init=y_0, v_init=vy_0)\n        x = self.x[id]\n        y = self.y[id]\n    else:\n        x = self.x[id]\n        y = self.y[id]\n    x.predict()\n    y.predict()\n    x.update([track[-1][0]])\n    y.update([track[-1][1]])\n</code></pre>"},{"location":"read_lidar/#read_lidar.SingleFrame","title":"<code>SingleFrame</code>","text":"<p>Class for representing single frame of data (scan).</p> Source code in <code>read_lidar.py</code> <pre><code>class SingleFrame:\n    \"\"\"Class for representing single frame of data (scan).\n    \"\"\"\n    def __init__(self, scan):\n        \"\"\"_summary_\n\n        Args:\n            scan (LidarScan): scan of environment\n        \"\"\"\n        self.sig_field = scan.field(client.ChanField.SIGNAL)\n\n    def get_combined_img(self, metadata):\n        \"\"\"Return combined image of black &amp; white image. It is used to determine the legal dimensions of the detector input.\n\n        Args:\n            metadata (SensorInfo): metadata file\n\n        Returns:\n            (np.ndarray): 3D black &amp; white image\n        \"\"\"\n        sig_destaggered = destagger(metadata, self.sig_field)\n        scaling_factor = 0.004\n        constant = 0.5\n        scaled_arr = sig_destaggered / (constant + scaling_factor * sig_destaggered)\n        signal_image = scaled_arr.astype(np.uint8)\n        combined_img = np.dstack((signal_image, signal_image, signal_image))\n        return combined_img\n\n    def get_xyz_destaggered(self, metadata, xyz_lut, scan):\n        \"\"\"Return destaggered scan\n\n        Args:\n            metadata (SensorInfo): metadata file\n            xyz_lut (XYZLut): lookup table for transformation to cartesian coordinate system\n            scan (LidarScan): single scan of environment\n\n        Returns:\n            (np.ndarray): A destaggered numpy array\n        \"\"\"\n        xyz_destaggered = client.destagger(metadata, xyz_lut(scan))\n        return xyz_destaggered\n</code></pre>"},{"location":"read_lidar/#read_lidar.SingleFrame.__init__","title":"<code>__init__(scan)</code>","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>scan</code> <code>LidarScan</code> <p>scan of environment</p> required Source code in <code>read_lidar.py</code> <pre><code>def __init__(self, scan):\n    \"\"\"_summary_\n\n    Args:\n        scan (LidarScan): scan of environment\n    \"\"\"\n    self.sig_field = scan.field(client.ChanField.SIGNAL)\n</code></pre>"},{"location":"read_lidar/#read_lidar.SingleFrame.get_combined_img","title":"<code>get_combined_img(metadata)</code>","text":"<p>Return combined image of black &amp; white image. It is used to determine the legal dimensions of the detector input.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>SensorInfo</code> <p>metadata file</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>3D black &amp; white image</p> Source code in <code>read_lidar.py</code> <pre><code>def get_combined_img(self, metadata):\n    \"\"\"Return combined image of black &amp; white image. It is used to determine the legal dimensions of the detector input.\n\n    Args:\n        metadata (SensorInfo): metadata file\n\n    Returns:\n        (np.ndarray): 3D black &amp; white image\n    \"\"\"\n    sig_destaggered = destagger(metadata, self.sig_field)\n    scaling_factor = 0.004\n    constant = 0.5\n    scaled_arr = sig_destaggered / (constant + scaling_factor * sig_destaggered)\n    signal_image = scaled_arr.astype(np.uint8)\n    combined_img = np.dstack((signal_image, signal_image, signal_image))\n    return combined_img\n</code></pre>"},{"location":"read_lidar/#read_lidar.SingleFrame.get_xyz_destaggered","title":"<code>get_xyz_destaggered(metadata, xyz_lut, scan)</code>","text":"<p>Return destaggered scan</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>SensorInfo</code> <p>metadata file</p> required <code>xyz_lut</code> <code>XYZLut</code> <p>lookup table for transformation to cartesian coordinate system</p> required <code>scan</code> <code>LidarScan</code> <p>single scan of environment</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>A destaggered numpy array</p> Source code in <code>read_lidar.py</code> <pre><code>def get_xyz_destaggered(self, metadata, xyz_lut, scan):\n    \"\"\"Return destaggered scan\n\n    Args:\n        metadata (SensorInfo): metadata file\n        xyz_lut (XYZLut): lookup table for transformation to cartesian coordinate system\n        scan (LidarScan): single scan of environment\n\n    Returns:\n        (np.ndarray): A destaggered numpy array\n    \"\"\"\n    xyz_destaggered = client.destagger(metadata, xyz_lut(scan))\n    return xyz_destaggered\n</code></pre>"},{"location":"read_lidar/#read_lidar.VideoProcessor","title":"<code>VideoProcessor</code>","text":"<p>Class for processing video.</p> Source code in <code>read_lidar.py</code> <pre><code>class VideoProcessor:\n    \"\"\"Class for processing video.\n    \"\"\"\n    def __init__(self, metadata:SensorInfo):\n        \"\"\"_summary_\n\n        Args:\n            metadata (SensorInfo): metadata file\n        \"\"\"\n        self.metadata = metadata\n\n    def process_video(self, scan:LidarScan, model:YOLOModel, track_history:HistoryTracker, kalman:HistoryTrackerXY, xyz_lut:XYZLut, output_dict:dict, ):\n        \"\"\"Function processing single scan of data.\n\n        Args:\n            scan (LidarScan): single scan\n            model (YOLOModel): detector\n            track_history (HistoryTracker): track history of all objects \n            kalman (HistoryTrackerXY): filtered track \n            xyz_lut (XYZLut): lookup table\n            output_dict (dict): contain priorities and the associated message\n\n        Returns:\n            (np.ndarray): image with annotations\n        \"\"\"\n        frame = SingleFrame(scan)\n        combined_img = frame.get_combined_img(self.metadata)\n        xyz_destaggered = frame.get_xyz_destaggered(self.metadata, xyz_lut, scan)\n        boxes, ids = model.track(source=combined_img)\n        priority = 3\n        distance = 0\n        for box, id in zip(boxes, ids):\n            center_x, center_y = int((box[0] + box[2])/2), int((box[1] + box[3])/2)\n            xyz_val = xyz_destaggered[(center_y, center_x)]\n            track_history.update_history(id=id, xyz_val=xyz_val)\n            track = track_history.get_track(id)\n            if len(track) &gt;= 2:\n                kalman.update(track, id)\n\n                out, distance = danger_sit(kalman.get_x_data(id), kalman.get_y_data(id), id)\n\n                if out &lt; priority:\n                    priority = out\n            cv2.rectangle(combined_img, (box[0], box[1]), (box[2], box[3]), output_dict[priority][1], 2)\n            cv2.rectangle(combined_img, (box[0], box[1]+2), (box[0]+160, box[1]-12), (255, 255, 255), -1)\n            cv2.putText(combined_img, f\"Id {id}; dist: {distance:0.2f} m\", (box[0], box[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n        cv2.putText(combined_img, f\"{output_dict[priority][0]}\", (470, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, output_dict[priority][1], 2)\n        return combined_img\n</code></pre>"},{"location":"read_lidar/#read_lidar.VideoProcessor.__init__","title":"<code>__init__(metadata)</code>","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>SensorInfo</code> <p>metadata file</p> required Source code in <code>read_lidar.py</code> <pre><code>def __init__(self, metadata:SensorInfo):\n    \"\"\"_summary_\n\n    Args:\n        metadata (SensorInfo): metadata file\n    \"\"\"\n    self.metadata = metadata\n</code></pre>"},{"location":"read_lidar/#read_lidar.VideoProcessor.process_video","title":"<code>process_video(scan, model, track_history, kalman, xyz_lut, output_dict)</code>","text":"<p>Function processing single scan of data.</p> <p>Parameters:</p> Name Type Description Default <code>scan</code> <code>LidarScan</code> <p>single scan</p> required <code>model</code> <code>YOLOModel</code> <p>detector</p> required <code>track_history</code> <code>HistoryTracker</code> <p>track history of all objects </p> required <code>kalman</code> <code>HistoryTrackerXY</code> <p>filtered track </p> required <code>xyz_lut</code> <code>XYZLut</code> <p>lookup table</p> required <code>output_dict</code> <code>dict</code> <p>contain priorities and the associated message</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>image with annotations</p> Source code in <code>read_lidar.py</code> <pre><code>def process_video(self, scan:LidarScan, model:YOLOModel, track_history:HistoryTracker, kalman:HistoryTrackerXY, xyz_lut:XYZLut, output_dict:dict, ):\n    \"\"\"Function processing single scan of data.\n\n    Args:\n        scan (LidarScan): single scan\n        model (YOLOModel): detector\n        track_history (HistoryTracker): track history of all objects \n        kalman (HistoryTrackerXY): filtered track \n        xyz_lut (XYZLut): lookup table\n        output_dict (dict): contain priorities and the associated message\n\n    Returns:\n        (np.ndarray): image with annotations\n    \"\"\"\n    frame = SingleFrame(scan)\n    combined_img = frame.get_combined_img(self.metadata)\n    xyz_destaggered = frame.get_xyz_destaggered(self.metadata, xyz_lut, scan)\n    boxes, ids = model.track(source=combined_img)\n    priority = 3\n    distance = 0\n    for box, id in zip(boxes, ids):\n        center_x, center_y = int((box[0] + box[2])/2), int((box[1] + box[3])/2)\n        xyz_val = xyz_destaggered[(center_y, center_x)]\n        track_history.update_history(id=id, xyz_val=xyz_val)\n        track = track_history.get_track(id)\n        if len(track) &gt;= 2:\n            kalman.update(track, id)\n\n            out, distance = danger_sit(kalman.get_x_data(id), kalman.get_y_data(id), id)\n\n            if out &lt; priority:\n                priority = out\n        cv2.rectangle(combined_img, (box[0], box[1]), (box[2], box[3]), output_dict[priority][1], 2)\n        cv2.rectangle(combined_img, (box[0], box[1]+2), (box[0]+160, box[1]-12), (255, 255, 255), -1)\n        cv2.putText(combined_img, f\"Id {id}; dist: {distance:0.2f} m\", (box[0], box[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n    cv2.putText(combined_img, f\"{output_dict[priority][0]}\", (470, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, output_dict[priority][1], 2)\n    return combined_img\n</code></pre>"},{"location":"read_lidar/#read_lidar.YOLOModel","title":"<code>YOLOModel</code>","text":"<p>Class for initialization of YOLO model and results of tracking.</p> Source code in <code>read_lidar.py</code> <pre><code>class YOLOModel:\n    \"\"\"\n    Class for initialization of YOLO model and results of tracking.\n    \"\"\"\n    def __init__(self, weights_path:str='./weights/best_3000_s_100.pt', imgsz=1024, tracker_path='trackers/bytetrack.yaml', persist=True, verbose=False):\n        \"\"\"\n        Initialization\n\n        Args:\n            weights_path (str, optional): Path to weights file. Defaults to './weights/best_3000_s_100.pt'.\n            imgsz (int, optional): Image size. Defaults to 1024.\n            tracker_path (str, optional): Path to tracker file. Defaults to 'trackers/bytetrack.yaml'.\n            persist (bool, optional): Defaults to True.\n            verbose (bool, optional): If print result of track to terminal. Defaults to False.\n        \"\"\"\n        self.model = YOLO(weights_path)\n        self.persist = persist\n        self.imgsz = imgsz\n        self.tracker = tracker_path\n        self.verbose = verbose\n\n    def track(self, source:np.ndarray)-&gt; tuple:\n        \"\"\"\n        Tracking objects.\n\n        Args:\n            source (np.ndarray): Image on witch tracker works.\n\n        Returns:\n            (tuple): List including boxes (xyxy) of tracked objects and list of their ids.\n        \"\"\"\n        results = self.model.track(source=source, persist=self.persist, imgsz=self.imgsz, tracker=self.tracker, verbose=self.verbose)\n        boxes = results[0].boxes.xyxy.cpu().numpy().astype(int)\n        if (results[0].boxes.id == None):\n            ids = ''\n        else:\n            ids = results[0].boxes.id.cpu().numpy().astype(int)\n        return boxes, ids\n</code></pre>"},{"location":"read_lidar/#read_lidar.YOLOModel.__init__","title":"<code>__init__(weights_path='./weights/best_3000_s_100.pt', imgsz=1024, tracker_path='trackers/bytetrack.yaml', persist=True, verbose=False)</code>","text":"<p>Initialization</p> <p>Parameters:</p> Name Type Description Default <code>weights_path</code> <code>str</code> <p>Path to weights file. Defaults to './weights/best_3000_s_100.pt'.</p> <code>'./weights/best_3000_s_100.pt'</code> <code>imgsz</code> <code>int</code> <p>Image size. Defaults to 1024.</p> <code>1024</code> <code>tracker_path</code> <code>str</code> <p>Path to tracker file. Defaults to 'trackers/bytetrack.yaml'.</p> <code>'trackers/bytetrack.yaml'</code> <code>persist</code> <code>bool</code> <p>Defaults to True.</p> <code>True</code> <code>verbose</code> <code>bool</code> <p>If print result of track to terminal. Defaults to False.</p> <code>False</code> Source code in <code>read_lidar.py</code> <pre><code>def __init__(self, weights_path:str='./weights/best_3000_s_100.pt', imgsz=1024, tracker_path='trackers/bytetrack.yaml', persist=True, verbose=False):\n    \"\"\"\n    Initialization\n\n    Args:\n        weights_path (str, optional): Path to weights file. Defaults to './weights/best_3000_s_100.pt'.\n        imgsz (int, optional): Image size. Defaults to 1024.\n        tracker_path (str, optional): Path to tracker file. Defaults to 'trackers/bytetrack.yaml'.\n        persist (bool, optional): Defaults to True.\n        verbose (bool, optional): If print result of track to terminal. Defaults to False.\n    \"\"\"\n    self.model = YOLO(weights_path)\n    self.persist = persist\n    self.imgsz = imgsz\n    self.tracker = tracker_path\n    self.verbose = verbose\n</code></pre>"},{"location":"read_lidar/#read_lidar.YOLOModel.track","title":"<code>track(source)</code>","text":"<p>Tracking objects.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>ndarray</code> <p>Image on witch tracker works.</p> required <p>Returns:</p> Type Description <code>tuple</code> <p>List including boxes (xyxy) of tracked objects and list of their ids.</p> Source code in <code>read_lidar.py</code> <pre><code>def track(self, source:np.ndarray)-&gt; tuple:\n    \"\"\"\n    Tracking objects.\n\n    Args:\n        source (np.ndarray): Image on witch tracker works.\n\n    Returns:\n        (tuple): List including boxes (xyxy) of tracked objects and list of their ids.\n    \"\"\"\n    results = self.model.track(source=source, persist=self.persist, imgsz=self.imgsz, tracker=self.tracker, verbose=self.verbose)\n    boxes = results[0].boxes.xyxy.cpu().numpy().astype(int)\n    if (results[0].boxes.id == None):\n        ids = ''\n    else:\n        ids = results[0].boxes.id.cpu().numpy().astype(int)\n    return boxes, ids\n</code></pre>"},{"location":"usage/","title":"Usage","text":"<ul> <li> <p>To run the code on your custom data, clone github repository: <pre><code>git clone https://github.com/SzewczykSzy/Dangerous-situations-with-pedastrians.git\n</code></pre></p> </li> <li> <p>Open this repository localy.</p> </li> <li> <p>Install all required packages: <pre><code>pip install -r requirements.txt\n</code></pre></p> </li> <li> <p>To run the code write in terminal: <pre><code>python ./detect_dangerous_situations.py --weights weights/best_3000_s_100.pt --pcap-path ../PATH_TO_PCAP_FILE/sample.pcap --metadata-path ../PATH_TO_JSON_FILE/sample.json --tracker ./trackers/bytetrack.yaml --imgsz 1024 --device cpu --save=0 --save-video-path C:/PATH_TO_REPOSITORY/Dangerous-situations-with-pedastrians/results_mp4/result.mp4\n</code></pre></p> </li> </ul> <p>Warning</p> <p>To stop the code while running press <code>q</code> on keyboard.</p> <p>Parameters:</p> Name Type Description Default <code>weights</code> <code>str</code> <p>path to trained YOLOv8 weights file.</p> <code>'weights/yolov5s.pt'</code> <code>pcap_path</code> <code>str</code> <p>path to <code>.pcap</code> file.</p> <code>'data/pcap/example.pcap'</code> <code>metadata_path</code> <code>str</code> <p>path to <code>.json</code> file.</p> <code>'data/json/example.json'</code> <code>tracker</code> <code>str</code> <p>path to tracker file <code>.yaml</code> with parameters.</p> <code>'weights/bytetracker.yaml'</code> <code>imgsz</code> <code>int</code> <p>image size.</p> <code>1024</code> <code>device</code> <code>str</code> <p>calculation on <code>cpu</code> or gpu (e.g. <code>0</code>, <code>1</code>).</p> <code>'cpu'</code> <code>save</code> <code>bool</code> <p>if want to save result video <code>1</code>, else <code>0</code>.</p> <code>False</code> <code>save_video_path</code> <code>str</code> <p>path to result video.</p> <code>''</code> Source code in <code>detect_dangerous_situations.py</code> <pre><code>def run(weights='weights/yolov5s.pt',\n        pcap_path='data/pcap/example.pcap',\n        metadata_path='data/json/example.json',\n        tracker = 'weights/bytetracker.yaml',\n        imgsz = 1024,\n        device = 'cpu',\n        save = False,\n        save_video_path = ''\n        ):\n    \"\"\"\n    Args:\n        weights (str, optional): path to trained YOLOv8 weights file.\n        pcap_path (str, optional): path to `.pcap` file.\n        metadata_path (str, optional): path to `.json` file.\n        tracker (str, optional): path to tracker file `.yaml` with parameters.\n        imgsz (int, optional): image size.\n        device (str, optional): calculation on `cpu` or gpu (e.g. `0`, `1`).\n        save (bool, optional): if want to save result video `1`, else `0`.\n        save_video_path (str, optional): path to result video.    \n    \"\"\"\n    yolo_model = YOLOModel(weights, imgsz=imgsz)\n    data_handler = DataHandler(metadata_path=metadata_path, pcap_path=pcap_path)\n    metadata = data_handler.get_metadata()\n    output_dict = data_handler.get_output_dict()\n    fps, width, height = data_handler.get_video_params()\n\n    video_processor = VideoProcessor(metadata=metadata)\n    history = HistoryTracker()\n    kalman = HistoryTrackerXY()\n\n    scans = data_handler.get_scans()\n    xyz_lut = data_handler.get_xyz_lut()\n    if save == 1:\n        vid_writer = cv2.VideoWriter(save_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n\n    for scan in scans:\n        image = video_processor.process_video(scan=scan, model=yolo_model, track_history=history, kalman=kalman, xyz_lut=xyz_lut, output_dict=output_dict)\n\n        cv2.imshow(\"YOLOv8 Tracking\", image)\n        cv2.waitKey(1)  # 1 millisecond\n        if cv2.waitKey(1) &amp; 0xFF == ord(\"q\"):\n            break\n\n        if save == 1:\n            vid_writer.write(image)\n\n    if save == 1:    \n        vid_writer.release()\n    cv2.destroyAllWindows()\n</code></pre>"}]}